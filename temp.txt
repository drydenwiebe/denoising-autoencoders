if torch.cuda.is_available():
    cuda = True
else:
    cuda = False

dataloader = customDataLoader(root_dir=os.getcwd() + data_location, batch_size=batch_size, split=1024)

class VAE(nn.Module):

    def __init__(self):
        super(VAE, self).__init__()

        '''
        encoder
        '''
        # conv layer (depth from 1 --> 32), 3x3 kernels
        self.conv1 = nn.Conv1d(1, 32, 11, padding=2)  
        # conv layer (depth from 32 --> 16), 3x3 kernels
        self.conv2 = nn.Conv1d(32, 16, 11, padding=1)
        # conv layer (depth from 16 --> 8), 3x3 kernels
        self.conv3 = nn.Conv1d(16, 8, 11, padding=1)
        # pooling layer to reduce x-y dims by two; kernel and stride of 2
        self.pool = nn.MaxPool1d(2, 2)
        # create a [batch_size, latent_space_size vector]
        self.conv_latent = nn.Conv1d(8, 1, 11, padding=1)

        self.fc1_1 = nn.Linear(49, latent_space_size)
        self.fc1_2 = nn.Linear(49, latent_space_size)

        '''
        decoder
        '''

        # transpose layer, a kernel of 2 and a stride of 2 will increase the spatial dims by 2
        self.t_conv1 = nn.ConvTranspose1d(8, 8, 3, stride=2)  # kernel_size=3 to get to a 7x7 image output
        # two more transpose layers with a kernel of 2
        self.t_conv2 = nn.ConvTranspose1d(8, 16, 2, stride=2)
        self.t_conv3 = nn.ConvTranspose1d(16, 32, 2, stride=2)
        # one, final, normal conv layer to decrease the depth
        self.conv_out = nn.Conv1d(32, 1, 3, padding=1)

        '''
        self.fc1 = nn.Linear(2048, 1024)
        self.LeakyReLU1 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc2 = nn.Linear(1024, 512)
        self.LeakyReLU2 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc3 = nn.Linear(512, 256)
        self.LeakyReLU3 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc4_1 = nn.Linear(256, latent_space_size)
        self.fc4_2 = nn.Linear(256, latent_space_size)
        self.fc5 = nn.Linear(latent_space_size, 256)
        self.LeakyReLU5 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc6 = nn.Linear(256, 512)
        self.LeakyReLU6 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc7 = nn.Linear(512, 1024)
        self.LeakyReLU7 = nn.LeakyReLU(negative_slope=negative_slope)
        self.fc8 = nn.Linear(1024, 2048)
        self.Tanh8 = nn.Tanh()
        '''

    def encode(self, x):
        '''
        encode
        '''
        # shape the input so that it has the correct number of channels
        #x = x.view(1, 2048)
        # add hidden layers with relu activation function
        # and maxpooling after
        x = F.relu(self.conv1(x))
        x = self.pool(x)

        print(x.shape)

        # add second hidden layer
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        # add third hidden layer
        x = F.relu(self.conv3(x))
        x = self.pool(x)  # compressed representation

        #print(x.shape)

        x = F.relu(self.conv_latent(x))

        #print(x.shape)

        x = x.view(-1, 49)

        return self.fc_1(x), self.fc_2(x)

        '''
        print(x.shape)

        x = x.view(batch_size, 1, 2048)

        print(x.shape)

        h = self.LeakyReLU1(self.conv1(x))

        print(h.shape)

        h1 = self.LeakyReLU1(self.fc1(x))
        h2 = self.LeakyReLU2(self.fc2(h1))
        h3 = self.LeakyReLU3(self.fc3(h2))
        return self.fc4_1(h3), self.fc4_2(h3)
        '''

    def reparametrize(self, mu, logvar):
        std = logvar.mul(0.5).exp_()

        if cuda:
            eps = torch.cuda.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()

        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def decode(self, z):
        h4 = self.LeakyReLU5(self.fc5(z))
        h5 = self.LeakyReLU6(self.fc6(h4))
        h6 = self.LeakyReLU7(self.fc7(h5))
        return self.Tanh8(self.fc8(h6))

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparametrize(mu, logvar)
        return self.decode(z), mu, logvar
    
    def generate(self):
        noise = torch.randn(1, latent_space_size, dtype=torch.float)
        return self.decode(noise)

model = VAE()
print(model)
if cuda:
    model.cuda()

@ignore_warnings
def set_reconstruction():
    return nn.MSELoss(size_average=False)

reconstruction_function = set_reconstruction()

def loss_function(recon_x, x, mu, logvar):

    '''
    recon_x: generated signals
    x: original signals
    mu: latent mean
    logvar: latent log variance
    '''

    BCE = reconstruction_function(recon_x, x)  # mse loss

    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.sum(KLD_element).mul_(-0.5)

    # KL divergence
    return BCE + KLD

optimizer = optim.Adam(model.parameters(), lr=learning_rate)

def train():
    for epoch in range(num_epochs):

        model.train()
        train_loss = 0

        for batch_idx, data in enumerate(dataloader.get_enumerable_list(), 0):

            signal = data

            print(signal.shape)

            signal = signal.view(signal.size(0), -1)

            print(signal.shape)

            signal = Variable(signal)

            if cuda:
                signal = signal.cuda()

            optimizer.zero_grad()

            recon_batch, mu, logvar = model(signal)

            loss = loss_function(recon_batch, signal, mu, logvar)

            loss.backward()

            train_loss += loss.item()

            optimizer.step()

            if batch_idx % 1 == 0:
                print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                    epoch,
                    batch_idx * len(signal),
                    len(dataloader) * batch_size, 100. * batch_idx / len(dataloader),
                    loss.item() / len(signal)))

        print('====> Epoch: {} Average loss: {:.4f}'.format(
            epoch,
            train_loss / (batch_size * len(dataloader))))

if __name__ == "__main__":
    train()

    model.eval()

    generated_signal = model.generate()[0].tolist()

    generated_reals = generated_signal[0:1024]
    generated_imaginaries = generated_signal[1024:]

    random_batch = random.randrange(0, 10)
    random_point = random.randrange(0, 10)

    plt.scatter(np.sort(generated_reals), np.sort(dataloader.get_enumerable_list().tolist()[random_batch][random_point][0:1024]))
    plt.show()

    plt.figure()
    plt.plot(np.asarray(generated_signal))
    plt.plot(np.asarray(dataloader.get_enumerable_list().tolist()[random_batch][random_point]))
    plt.show()
